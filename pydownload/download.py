import os
import json
import aiohttp
import asyncio
import zipfile  # å»ºè®®å°†å¯¼å…¥æ”¾åœ¨æ–‡ä»¶é¡¶éƒ¨

MAX_CONCURRENT_FILES = 8  # åŒæ—¶ä¸‹è½½çš„æ–‡ä»¶æ•°
CHUNK_SIZE = 1024 * 1024  # 1MB åˆ†å—


async def download_file(session, file_info, target_dir):
    url = file_info['url']
    filename = file_info['filename']
    unzip = file_info.get('unzip', False)
    save_path = os.path.join(target_dir, filename)

    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆé˜²é‡å¤ä¸‹è½½ï¼‰
    if os.path.exists(save_path):
        print(f"â­ï¸  è·³è¿‡ (å·²å­˜åœ¨): {filename}")
        return

    # 2. ç¡®è®¤ä¸å­˜åœ¨åï¼Œæç¤ºå¼€å§‹ä¸‹è½½
    print(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½: {filename}")

    try:
        async with session.get(url) as resp:
            resp.raise_for_status()
            with open(save_path, 'wb') as f:
                async for chunk in resp.content.iter_chunked(CHUNK_SIZE):
                    f.write(chunk)

        print(f"âœ… ä¸‹è½½å®Œæˆ: {filename}")

        # 3. å¦‚æœéœ€è¦è§£å‹
        if unzip and save_path.endswith('.zip'):
            try:
                with zipfile.ZipFile(save_path, 'r') as zip_ref:
                    zip_ref.extractall(target_dir)
                print(f"ğŸ“¦ è§£å‹å®Œæˆ: {filename}")
            except zipfile.BadZipFile:
                print(f"âš ï¸  è§£å‹å¤±è´¥ (æ–‡ä»¶æŸå): {filename}")
            except Exception as e:
                print(f"âš ï¸  è§£å‹å‡ºé”™: {e}")

    except Exception as e:
        # 4. ä¸‹è½½å¤±è´¥å¤„ç†ï¼šåˆ é™¤å¯èƒ½äº§ç”Ÿçš„åŠæˆå“æ–‡ä»¶ï¼Œé˜²æ­¢ä¸‹æ¬¡è¯¯åˆ¤ä¸ºå·²å­˜åœ¨
        if os.path.exists(save_path):
            try:
                os.remove(save_path)
            except OSError:
                pass
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url}: {e}")


async def process_json(json_path, session):
    target_dir = os.path.dirname(json_path)
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = [download_file(session, file_info, target_dir) for file_info in data.get('files', [])]

        if tasks:
            await asyncio.gather(*tasks)

    except Exception as e:
        print(f"âŒ å¤„ç† JSON å¤±è´¥ {json_path}: {e}")


async def main():
    # è·å– resources ç›®å½•çš„ç»å¯¹è·¯å¾„
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'resources'))

    json_files = []
    # é€’å½’æŸ¥æ‰¾ json æ–‡ä»¶
    for root, _, files in os.walk(base_dir):
        for file in files:
            if file.lower().endswith('.json'):
                json_files.append(os.path.join(root, file))

    if not json_files:
        print("æœªåœ¨ resources ç›®å½•ä¸‹æ‰¾åˆ° JSON é…ç½®æ–‡ä»¶ã€‚")
        return

    print(f"å‘ç° {len(json_files)} ä¸ªé…ç½®æ–‡ä»¶ï¼Œå‡†å¤‡å¤„ç†...")

    connector = aiohttp.TCPConnector(limit_per_host=MAX_CONCURRENT_FILES)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [process_json(jf, session) for jf in json_files]
        await asyncio.gather(*tasks)


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ›” ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ç¨‹åº")